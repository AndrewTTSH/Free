# -*- coding: utf-8 -*-
"""Reload Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rF4gQzKlEf7o98CiIBbKVPkAiUNVxnUE

Please be careful before you run this script. Why? The reason is - this script just deletes your Pinecone index. All your vector data are stored in the Pinecone index vector database. When you delete the vector index, all your data are permanently deleted. So, please careful!

# Step 1: Install necessary Python packages

Without installing these Python packages, our program will not run. So, we must install them at the very beginning.

If you want to delete the Pinecone index from your laptop or desktop, it is not an efficient idea because it may take longer time. When you use Google Colab for this task, it will be faster and efficient.
"""

!pip install openai
!pip install pinecone-client
!pip install langchain
!pip install unstructured

"""# Step 2: Upload your PDF files

At this point, create a folder named as "pdf" and upload all your PDF files in this folder. To create a folder, do these:
1. click on the folder icon from the left sidebar
2. Right click --> New folder
3. Rename it to "pdf"

# Step 3: Setup/configure OpenAI & Pinecone

At this point of time, we must setup/configure these two packages
"""

# Setup/configure OpenAI
import openai
import os

OPENAI_API_KEY = "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"
openai.api_key = OPENAI_API_KEY
os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# Setup/configure Pinecone
import pinecone

# initialize connection to pinecone (get API key at app.pinecone.io)
pinecone.init(
    api_key="4907cba7-f52a-4211-b521-e5b6ce57db17",
    environment="us-west1-gcp-free"  # find next to API key in console
)

"""# Step 4: Confirm that you are sure that you want to delete the index

To avoid accidental index deletion, I have added a check that asks for your consent before you delete the index.

I have used my Pinecone API Key and Environment name. Please remember to remove them and use your own Pinecone API Key and Environment name.

There are three checks in this stage:
1. Did you already create a folder named as "pdf"?
2. Did you upload any file with ".pdf" extension?
3. Did you give your consent by typing "yes"?

The script will not delete the existing Pinecone index until the above requirements are fulfilled.

Please feel free to change the "index_name" name. The index name does not matter. Any valid index name will do.
"""

# importing os modules
import os
from os import listdir
from os.path import isfile, join

index_name = "langchain-pdf"
is_consent_given = False
pdf_file_directory_path = "pdf"
total_pdf = 0

isExist = os.path.exists(pdf_file_directory_path)

if isExist:
  print('Great! You have already created the "pdf" folder.')

  # Get the list of all files and directories
  file_name_list = [f for f in listdir(pdf_file_directory_path) if isfile(join(pdf_file_directory_path, f))]

  for file_name in file_name_list:
    # unpacking the tuple
    file_name, file_extension = os.path.splitext(file_name)

    if file_extension == '.pdf':
      total_pdf = total_pdf + 1

  if total_pdf > 0:
    print('Great! You have uploaded {} PDF files.'.format(total_pdf))

    consent = input("Do you really want to delete your Pinecone Index Database {}?\nType yes/no: ".format(index_name))
    consent = consent.lower()

    if (consent == 'yes'):
      is_consent_given = True
      print("You have selected to delete your Pinecone vector index database: {}.".format(index_name))
    else:
      print("You do NOT want to deleteyour Pinecone vector index database: {}.\nSo, no action will be taken.".format(index_name))

  else:
    print('Oops! Upload at least one PDF file and try again.')
else:
  print('Oops! You have not created the "pdf" folder.\nPlease create this folder and try again.')

"""Step 5: Delete the Pinecone Index (if any)

If the selected index exists, we shall delete it now.
"""

is_vector_index_deleted = False

# Check if the index already exists
# We shall try to delete it only if it exists
if index_name not in pinecone.list_indexes():
  is_vector_index_deleted = True
  print("Great! Your selected Pinecone vector index {} does not exist.".format(index_name))
else:
  print('Before we delete your Pinecone vector index, here is the stats:')
  # connect to index
  index = pinecone.Index(index_name)
  # view index stats
  index.describe_index_stats()

  pinecone.delete_index(index_name)
  if index_name not in pinecone.list_indexes():
    is_vector_index_deleted = True
    print("Great! Your selected Pinecone vector index {} is deleted.\nNow you can reload fresh data from your PDF files.".format(index_name))
  else:
    print('Oops! The script has failed to delete your existing Pinecone vector index: {}'.format(index_name))

"""# Step 6: Create a new Pinecone vector index

Now we shall re-create a new vector index.

This step may take some time to finish. So, please hold on and wait.
"""

is_ready_to_upload_data = False
embed_model = "text-embedding-ada-002"

res = openai.Embedding.create(
    input=[
        'This is a test line to get the "embedding" data.',
    ], engine=embed_model
)

embedding = res['data'][0]['embedding']
# extract embeddings to a list
embeds = [record['embedding'] for record in res['data']]

if is_vector_index_deleted == True:
  if index_name not in pinecone.list_indexes():
    pinecone.create_index(index_name, dimension=len(embeds[0]))

  if index_name not in pinecone.list_indexes():
    print('Oops! A new Pinecone vector index "{}" could not be created.\nPlease try again.'.format(index_name))
  else:
    is_ready_to_upload_data = True
    print('Great! A new Pinecone vector index "{}" is created.'.format(index_name))

"""# Step 7: Upload data to the new Pinecone vector index

Finally, we shall load data from the PDF files, convert them to vectors and insert these vectors into our newly created vector index.

This step may take a long time to finish. So, please hold on and wait.
"""

from langchain.document_loaders import UnstructuredFileLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Pinecone

# Connect to index
index = pinecone.Index(index_name)
# View index stats
#index.describe_index_stats()
# Ceate a vector store
#vectorstore = Pinecone(index, embeddings.embed_query, "text")

#print(type("More text!"))
# We need to use OpenAI's embeddings
embeddings = OpenAIEmbeddings()


# Now we shall loop through each file, get content, convert to vectors and upload to a vector database
for file_name in file_name_list:
  file_path = '{}/{}'.format(pdf_file_directory_path, file_name)
  print(file_path)
  loader = UnstructuredFileLoader(file_path, mode="elements")
  documents = loader.load()
  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0, length_function = len)
  docs = text_splitter.split_documents(documents)

  counter = 0
  for doc in docs:
    counter = counter + 1
    if counter <= 3:
      print('doc.page_content: {}'.format(doc.page_content))
      print('----------------------------------------------------')
      # We need to use OpenAI's embeddings
      # embeddings = OpenAIEmbeddings()
      # Ceate a vector store
      vectorstore = Pinecone(index, embeddings.embed_query, "text")
      vectorstore.add_texts(doc.page_content)

"""# Step 8: Check the stats of your new vector index database

Here you see some basic data.
"""

# connect to index
index = pinecone.Index(index_name)
# view index stats
index.describe_index_stats()

# Commented out IPython magic to ensure Python compatibility.
# %autosave 60